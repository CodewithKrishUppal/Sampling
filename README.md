# Sampling
The solution applies technique to resolve class imbalance in a dataset by systematically applying various resampling techniques and evaluating the performance of multiple machine learning models. Class imbalance, where one class significantly outnumbers the other, can lead to biased models that perform poorly on the minority class. To address this issue, the code employs resampling techniques such as Random Over Sampling, Random Under Sampling, SMOTE, ADASYN, and NearMiss. These techniques are applied to the training data, creating balanced datasets for training machine learning models.

The models selected for evaluation include Random Forest, Logistic Regression, Naive Bayes, K-Nearest Neighbors, and Decision Tree. These models represent diverse approaches to classification and are trained on the resampled datasets. For each combination of resampling technique and machine learning model, accuracy scores are calculated and stored in a structured format. The results are organized into a Pandas DataFrame, facilitating easy comparison and analysis.

To provide a comprehensive view of the model performances, the code creates a pivot table that displays the accuracy results in a tabular format. Each row corresponds to a machine learning model, while columns represent different resampling techniques. This arrangement allows for a quick assessment of how each model fares under various sampling strategies. Furthermore, the code identifies the best-performing resampling technique for each model based on the highest accuracy, presenting this information in a separate DataFrame. Overall, this systematic and organized approach assists in gaining insights into the impact of resampling techniques on model performance, aiding in the selection of optimal strategies for handling class imbalance in classification tasks.
